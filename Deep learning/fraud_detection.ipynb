{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name np_utils",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-d892e225bbdb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpylab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\saite\\Anaconda2\\Anaconda2\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\saite\\Anaconda2\\Anaconda2\\lib\\site-packages\\keras\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name np_utils"
     ]
    }
   ],
   "source": [
    "from pylab import rcParams\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "LABELS = [\"Normal\", \"Fraud\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data\n",
    "\n",
    "The dataset we're going to use can be downloaded from [Kaggle](https://www.kaggle.com/dalpozz/creditcardfraud). It contains data about credit card transactions that occurred during a period of two days, with 492 frauds out of 284,807 transactions.\n",
    "\n",
    "All variables in the dataset are numerical. The data has been transformed using PCA transformation(s) due to privacy reasons. The two features that haven't been changed are Time and Amount. Time contains the seconds elapsed between each transaction and the first transaction in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31 columns, 2 of which are Time and Amount. The rest are output from the PCA transformation. Let's check for missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_classes = pd.value_counts(df['Class'], sort = True)\n",
    "count_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEWCAYAAACwtjr+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIqr7//xLIMVIVQF2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa163550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_classes.plot(kind = 'bar', rot=0)\n",
    "plt.title(\"Transaction class distribution\")\n",
    "plt.xticks(range(2), LABELS)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data\n",
    "\n",
    "First, let's drop the Time column (not going to use it) and use the scikit's StandardScaler on the Amount. The scaler removes the mean and scales the values to unit variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...         V21       V22       V23  \\\n",
       "0  0.098698  0.363787  0.090794  ...   -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974  ...   -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643  ...    0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952  ...   -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074  ...   -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Amount  Class  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.drop(['Time'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>1.768627e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>5.085503e-16</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>1.088850e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.709250e-01</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>-2.458826e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.449772e+01</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>-5.354257e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.117214e-01</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>-9.291738e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.248109e-02</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>4.539234e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.330408e-01</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>2.374514e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.942090e+01</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 V1            V2            V3            V4            V5  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15 -1.552563e-15   \n",
       "std    1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00  1.380247e+00   \n",
       "min   -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00 -1.137433e+02   \n",
       "25%   -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01 -6.915971e-01   \n",
       "50%    1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02 -5.433583e-02   \n",
       "75%    1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01  6.119264e-01   \n",
       "max    2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01  3.480167e+01   \n",
       "\n",
       "                 V6            V7            V8            V9           V10  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15  1.768627e-15   \n",
       "std    1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00  1.088850e+00   \n",
       "min   -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01 -2.458826e+01   \n",
       "25%   -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01 -5.354257e-01   \n",
       "50%   -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02 -9.291738e-02   \n",
       "75%    3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01  4.539234e-01   \n",
       "max    7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01  2.374514e+01   \n",
       "\n",
       "           ...                 V20           V21           V22           V23  \\\n",
       "count      ...        2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...        5.085503e-16  1.537294e-16  7.959909e-16  5.367590e-16   \n",
       "std        ...        7.709250e-01  7.345240e-01  7.257016e-01  6.244603e-01   \n",
       "min        ...       -5.449772e+01 -3.483038e+01 -1.093314e+01 -4.480774e+01   \n",
       "25%        ...       -2.117214e-01 -2.283949e-01 -5.423504e-01 -1.618463e-01   \n",
       "50%        ...       -6.248109e-02 -2.945017e-02  6.781943e-03 -1.119293e-02   \n",
       "75%        ...        1.330408e-01  1.863772e-01  5.285536e-01  1.476421e-01   \n",
       "max        ...        3.942090e+01  2.720284e+01  1.050309e+01  2.252841e+01   \n",
       "\n",
       "                V24           V25           V26           V27           V28  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   4.458112e-15  1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16   \n",
       "std    6.056471e-01  5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01   \n",
       "min   -2.836627e+00 -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01   \n",
       "25%   -3.545861e-01 -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02   \n",
       "50%    4.097606e-02  1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02   \n",
       "75%    4.395266e-01  3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02   \n",
       "max    4.584549e+00  7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   \n",
       "\n",
       "              Amount  \n",
       "count  284807.000000  \n",
       "mean       88.349619  \n",
       "std       250.120109  \n",
       "min         0.000000  \n",
       "25%         5.600000  \n",
       "50%        22.000000  \n",
       "75%        77.165000  \n",
       "max     25691.160000  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " data.loc[:,'V1':'Amount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 149.62,    2.69,  378.66, ...,   67.88,   10.  ,  217.  ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Amount'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 149.62],\n",
       "       [   2.69],\n",
       "       [ 378.66],\n",
       "       ..., \n",
       "       [  67.88],\n",
       "       [  10.  ],\n",
       "       [ 217.  ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Amount'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.34961925087359"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Amount'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250.1201092402221"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Amount'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.244964\n",
       "1        -0.342474\n",
       "2         1.160684\n",
       "3         0.140534\n",
       "4        -0.073403\n",
       "5        -0.338556\n",
       "6        -0.333278\n",
       "7        -0.190107\n",
       "8         0.019392\n",
       "9        -0.338516\n",
       "10       -0.322044\n",
       "11       -0.313288\n",
       "12        0.132538\n",
       "13       -0.243282\n",
       "14       -0.118142\n",
       "15       -0.289299\n",
       "16       -0.301294\n",
       "17       -0.349670\n",
       "18       -0.166119\n",
       "19       -0.333238\n",
       "20        0.573166\n",
       "21       -0.216934\n",
       "22       -0.344113\n",
       "23       -0.262272\n",
       "24       -0.349670\n",
       "25       -0.247560\n",
       "26       -0.185789\n",
       "27       -0.289260\n",
       "28       -0.221292\n",
       "29       -0.301294\n",
       "            ...   \n",
       "284777   -0.349231\n",
       "284778   -0.033382\n",
       "284779   -0.253277\n",
       "284780   -0.233286\n",
       "284781   -0.301254\n",
       "284782   -0.301973\n",
       "284783   -0.307411\n",
       "284784   -0.193306\n",
       "284785   -0.346072\n",
       "284786   -0.317446\n",
       "284787   -0.313288\n",
       "284788   -0.337276\n",
       "284789   -0.111345\n",
       "284790   -0.314008\n",
       "284791   -0.271988\n",
       "284792   -0.337276\n",
       "284793   -0.333278\n",
       "284794   -0.349670\n",
       "284795   -0.313768\n",
       "284796   -0.113344\n",
       "284797   -0.331279\n",
       "284798   -0.257075\n",
       "284799   -0.033422\n",
       "284800   -0.342514\n",
       "284801   -0.342474\n",
       "284802   -0.350150\n",
       "284803   -0.254116\n",
       "284804   -0.081839\n",
       "284805   -0.313248\n",
       "284806    0.514354\n",
       "Name: Amount, Length: 284807, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data['Amount'] - 88.34961925087359)/250.1201092402221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.244964\n",
       "1        -0.342475\n",
       "2         1.160686\n",
       "3         0.140534\n",
       "4        -0.073403\n",
       "5        -0.338556\n",
       "6        -0.333279\n",
       "7        -0.190107\n",
       "8         0.019392\n",
       "9        -0.338516\n",
       "10       -0.322044\n",
       "11       -0.313289\n",
       "12        0.132538\n",
       "13       -0.243282\n",
       "14       -0.118142\n",
       "15       -0.289300\n",
       "16       -0.301294\n",
       "17       -0.349671\n",
       "18       -0.166119\n",
       "19       -0.333239\n",
       "20        0.573167\n",
       "21       -0.216935\n",
       "22       -0.344114\n",
       "23       -0.262273\n",
       "24       -0.349671\n",
       "25       -0.247560\n",
       "26       -0.185790\n",
       "27       -0.289260\n",
       "28       -0.221293\n",
       "29       -0.301294\n",
       "            ...   \n",
       "284777   -0.349231\n",
       "284778   -0.033382\n",
       "284779   -0.253277\n",
       "284780   -0.233287\n",
       "284781   -0.301254\n",
       "284782   -0.301974\n",
       "284783   -0.307411\n",
       "284784   -0.193306\n",
       "284785   -0.346073\n",
       "284786   -0.317447\n",
       "284787   -0.313289\n",
       "284788   -0.337277\n",
       "284789   -0.111345\n",
       "284790   -0.314008\n",
       "284791   -0.271988\n",
       "284792   -0.337277\n",
       "284793   -0.333279\n",
       "284794   -0.349671\n",
       "284795   -0.313768\n",
       "284796   -0.113344\n",
       "284797   -0.331280\n",
       "284798   -0.257075\n",
       "284799   -0.033422\n",
       "284800   -0.342515\n",
       "284801   -0.342475\n",
       "284802   -0.350151\n",
       "284803   -0.254117\n",
       "284804   -0.081839\n",
       "284805   -0.313249\n",
       "284806    0.514355\n",
       "Name: Amount, Length: 284807, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "data['Amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training our Autoencoder is gonna be a bit different from what we are used to. Let's say you have a dataset containing a lot of non fraudulent transactions at hand. You want to detect any anomaly on new transactions. We will create this situation by training our model on the normal transactions, only. Reserving the correct class on the test set will give us a way to evaluate the performance of our model. We will reserve 20% of our data for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.35980713, -0.07278117,  2.53634674, ..., -0.02105305,\n",
       "         0.24496426,  0.        ],\n",
       "       [ 1.19185711,  0.26615071,  0.16648011, ...,  0.01472417,\n",
       "        -0.34247454,  0.        ],\n",
       "       [-1.35835406, -1.34016307,  1.77320934, ..., -0.05975184,\n",
       "         1.16068593,  0.        ],\n",
       "       ..., \n",
       "       [ 1.91956501, -0.30125385, -3.24963981, ..., -0.02656083,\n",
       "        -0.0818393 ,  0.        ],\n",
       "       [-0.24044005,  0.53048251,  0.70251023, ...,  0.10453282,\n",
       "        -0.31324853,  0.        ],\n",
       "       [-0.53341252, -0.18973334,  0.70333737, ...,  0.01364891,\n",
       "         0.51435531,  0.        ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(data, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train[X_train[:,-1] == 0]\n",
    "X_train = X_train[:,:-1]\n",
    "\n",
    "y_test = X_test[:,-1]\n",
    "X_test = X_test[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227451L, 29L)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model\n",
    "\n",
    "Building an autoencoder with 15 hidden layer neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-e869cc640e5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mencoding_dim\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mautoencoder\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "input_dim= X_train.shape[1]\n",
    "encoding_dim= 15 \n",
    "\n",
    "autoencoder= Sequential()\n",
    "autoencoder.add(Dropout(0.2, input_shape=(input_dim,)))\n",
    "autoencoder.add(Dense(20, activation='sigmoid'))\n",
    "autoencoder.add(Dense(encoding_dim, activation='relu'))\n",
    "autoencoder.add(Dense(20, activation='sigmoid'))\n",
    "autoencoder.add(Dense( input_dim,activation='linear'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling the Model \n",
    "Let's train our model for 100 epochs with a batch size of 32 samples. Write the code for compiling and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'autoencoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-611826cfe33a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m autoencoder.compile(optimizer='adam',loss='mean_squared_error',\n\u001b[0m\u001b[0;32m      5\u001b[0m                    metrics=['mse'])\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'autoencoder' is not defined"
     ]
    }
   ],
   "source": [
    "nb_epoch=100\n",
    "batch_size= 32 \n",
    "\n",
    "autoencoder.compile(optimizer='adam',loss='mean_squared_error',\n",
    "                   metrics=['mse'])\n",
    "\n",
    "history= autoencoder.fit(X_train,X_train,\n",
    "                         epochs=nb_epoch,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle= True,\n",
    "                         validation_data=(X_test, X_test),\n",
    "                         verbose=1).history \n",
    "                         \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history['mean_squared_error'])\n",
    "plt.plot(history['val_mean_squared_error'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reconstruction error on our training and test data seems to converge nicely. Is it low enough? Let's have a closer look at the error distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score,recall_score\n",
    "\n",
    "prc = list()\n",
    "rec = list()\n",
    "thres = list()\n",
    "\n",
    "th = 0\n",
    "for i in range(100):\n",
    "    th+=0.1\n",
    "    fraud = (test_recon>mean_recon+th)\n",
    "    prc.append(precision_score(y_test,fraud))\n",
    "    rec.append(recall_score(y_test,fraud))\n",
    "    thres.append(th)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(prc, rec)\n",
    "plt.title('precision vs recall')\n",
    "plt.ylabel('recall')\n",
    "plt.xlabel('precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(thres, rec)\n",
    "plt.title('threshold vs recall')\n",
    "plt.ylabel('recall')\n",
    "plt.xlabel('threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(thres, prc)\n",
    "plt.title('threshold vs precision')\n",
    "plt.ylabel('precision')\n",
    "plt.xlabel('threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
