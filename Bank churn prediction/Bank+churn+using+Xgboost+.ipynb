{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import lib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#current path \n",
    "import os \n",
    "print (os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set path \n",
    "os.chdir('C:\\\\Users\\\\saite\\\\Documents\\\\Bank data AV hack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load the data using pandas\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "test['Responders'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine data for performing Feature Engineering\n",
    "combin = pd.concat([train,test])\n",
    "combin.replace('Y', 1, inplace = True)\n",
    "combin.replace('N', 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replacing all nans in time series variables by zero\n",
    "combin.iloc[:,11:11 + 39 * 6].fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_c_cols = [col for col in combin.iloc[:,11:50].columns]\n",
    "d_c_cols = [element[:-1] for element in d_c_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create new features from the last 3 months using some measures including max, min, mean and standard deviation\n",
    "for col in d_c_cols:\n",
    "    col2 = [column for column in combin.columns if col in column]\n",
    "    combin['Last_3_month_average_' + str(col)]  = combin[col2].mean(axis = 1)\n",
    "    combin['Last_3_month_max_' + str(col)]  = combin[col2].max(axis = 1)\n",
    "    combin['Last_3_month_min_' + str(col)]  = combin[col2].min(axis = 1)\n",
    "    combin['Last_3_month_std_' + str(col)]  = combin[col2].std(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop in Debit amount as a percentage of the avg monthly balance\n",
    "for i in np.arange(1,6):\n",
    "    combin['custinit_DR_amt_Drop_Build_'+ str(i)] = (combin['custinit_DR_amt_prev' + str(i+1)] - combin['custinit_DR_amt_prev' + str(i)])/(1 + combin['BAL_prev' + str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Difference between end of month balance and average balance of each month as percentage of avg balance\n",
    "for i in np.arange(1,7):\n",
    "    combin['EOP_BAL_DIFF_prev' + str(i)] = (combin['EOP_prev' + str(i)] - combin['BAL_prev'+ str(i)])/combin['BAL_prev' + str(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standard Deviation for the above generated feature(list comprihension with condition)\n",
    "eop_bal_cols = [col for col in combin.columns if 'EOP_BAL_DIFF' in col]\n",
    "combin['STD_EOP_BAL_DIFF_prev'] = combin[eop_bal_cols].std(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Measures generated from percentage change in credit amount for each pair of consecutive months\n",
    "cr_amb_drop_cols = ['CR_AMB_Drop_Build_1','CR_AMB_Drop_Build_2','CR_AMB_Drop_Build_3']\n",
    "combin['Mean_CR_AMB_Drop_Build'] = combin[cr_amb_drop_cols].mean(axis = 1)\n",
    "combin['STD_CR_AMB_Drop_Build'] = combin[cr_amb_drop_cols].std(axis = 1)\n",
    "combin['MIN_CR_AMB_Drop_Build'] = combin[cr_amb_drop_cols].min(axis = 1)\n",
    "combin['Weighted_Sum_CR_AMB_Drop_Build'] = 1 * (combin['CR_AMB_Drop_Build_1'] < 0) + 0.8 * \n",
    "(combin['CR_AMB_Drop_Build_2'] < 0) + 0.6 * (combin['CR_AMB_Drop_Build_3'] < 0) + \n",
    "0.4 *(combin['CR_AMB_Drop_Build_4'] < 0) + 0.2 * (combin['CR_AMB_Drop_Build_5'] < 0)\n",
    "\n",
    "i_cnr_prev = ['I_CNR_PrevQ1','I_CNR_PrevQ2']\n",
    "i_aqb_prev = ['I_AQB_PrevQ1','I_AQB_PrevQ1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change in quarterly average balance\n",
    "combin['I_AQB_CHANGE'] = (combin['I_AQB_PrevQ1'] - combin['I_AQB_PrevQ2'])\n",
    "combin['I_NRV_CHANGE'] = (combin['I_NRV_PrevQ1'] - combin['I_NRV_PrevQ2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Average of quarterly customer net revenue and quarterly balance\n",
    "combin['Mean_I_CNR_PrevQ'] = combin[i_cnr_prev].mean(axis = 1)\n",
    "combin['Mean_I_AQB_PrevQ'] = combin[i_aqb_prev].mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sum of average debit and credit transactions in the past 3 months \n",
    "combin['Total_Count_txn'] = (combin['Last_3_month_average_count_C_prev'] + combin['Last_3_month_average_count_D_prev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Percentage of transactions via each mode - branch, atm and mobile banking\n",
    "combin['percent_txn_branch'] = (combin['Last_3_month_average_COUNT_BRANCH_C_prev'] + combin['Last_3_month_average_COUNT_BRANCH_D_prev'])/combin['Total_Count_txn']\n",
    "combin['percent_txn_atm'] = (combin['Last_3_month_average_COUNT_ATM_C_prev'] + combin['Last_3_month_average_COUNT_ATM_D_prev'])/combin['Total_Count_txn']\n",
    "combin['percent_txn_phn_mob'] = (combin['Last_3_month_average_COUNT_IB_C_prev'] + combin['Last_3_month_average_COUNT_IB_D_prev'] + combin['Last_3_month_average_COUNT_MB_C_prev'] + combin['Last_3_month_average_COUNT_MB_D_prev'])/combin['Total_Count_txn']\n",
    "percent_change_cols = ['Percent_Change_in_Credits', 'Percent_Change_in_FT_Bank', 'Percent_Change_in_FT_outside', 'Percent_Change_in_Self_Txn', 'Percent_Change_in_Big_Expenses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Median percentage change for all modes of transaction\n",
    "combin['Median_Percent_change'] = combin[percent_change_cols].median(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Label encoding some categorical features\n",
    "dict_hnw = {'3_Classic': 3, '2_Preferred': 2, '1_Imperia':1}\n",
    "combin.replace({\"HNW_CATEGORY\": dict_hnw}, inplace=True)\n",
    "\n",
    "dict_fw = {'HIGH': 3, 'MEDIUM': 2, 'LOW':1}\n",
    "combin.replace({\"FINAL_WORTH_prev1\": dict_fw}, inplace=True)\n",
    "\n",
    "dict_eng = {'HIGH': 3, 'MEDIUM': 2, 'LOW':1, 'NO':-1}\n",
    "combin.replace({'ENGAGEMENT_TAG_prev1': dict_eng}, inplace=True)\n",
    "\n",
    "dict_rbi_ca = {'METROPOLITAN': 3, 'URBAN': 2, 'SEMI-URBAN':1, 'RURAL':0}\n",
    "combin.replace({'RBI_Class_Audit': dict_rbi_ca}, inplace=True)\n",
    "\n",
    "dict_billpay = {'A_MISSING': -9999, 'B_1':1, 'C_2':2, 'D_3':3}\n",
    "combin.replace({'Billpay_Active_PrevQ1_N': dict_billpay}, inplace=True)\n",
    "combin.replace({'Billpay_Reg_ason_Prev1_N': dict_billpay}, inplace=True)\n",
    "combin.replace({'Charges_cnt_PrevQ1_N': dict_billpay}, inplace=True)\n",
    "combin.replace({'FRX_PrevQ1_N': dict_billpay}, inplace=True)\n",
    "\n",
    "dict_gender = {'Male': 1, 'Female':0, 'Missin':-1}\n",
    "combin.replace({'gender_bin': dict_gender}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert city variable wrt degree of number of customers\n",
    "combin['new_city'] = combin['city']\n",
    "counts = combin.city.value_counts()\n",
    "combin.new_city[combin['new_city'].isin(counts[counts > 9000].index)] = 3\n",
    "combin.new_city[combin['new_city'].isin(counts[counts < 9000].index) & combin['new_city'].isin(counts[counts >= 3500].index)] = 2\n",
    "combin.new_city[combin['new_city'].isin(counts[counts < 3500].index) & combin['new_city'].isin(counts[counts >= 1000].index)] = 1\n",
    "combin.new_city[combin['new_city'].isin(counts[counts < 1000].index)] = 0\n",
    "combin['zip'] = combin['zip'].astype('object')\n",
    "combin['zip_first_3'] = combin['zip'].str[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert occupation to one hot encoded features\n",
    "combin = pd.concat([combin,pd.get_dummies(combin['OCCUP_ALL_NEW'],prefix = str('OCCUP_ALL_NEW'),prefix_sep='_')],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create derived features from the loan specific information\n",
    "prem_cols = [col for col in combin.columns if 'PREM_CLOSED' in col]\n",
    "\n",
    "combin['any_prematurely_closed_loans'] = combin[prem_cols].sum(axis = 1)\n",
    "loan_closed_cols = ['AGRI_Closed_PrevQ1', 'AL_CNC_Closed_PrevQ1', 'AL_Closed_PrevQ1', 'BL_Closed_PrevQ1', 'CC_CLOSED_PREVQ1',\n",
    "                    'CE_Closed_PrevQ1', 'CV_Closed_PrevQ1', 'EDU_Closed_PrevQ1', 'GL_Closed_PrevQ1', 'OTHER_LOANS_Closed_PrevQ1', \n",
    "                    'PL_Closed_PrevQ1', 'RD_CLOSED_PREVQ1', 'FD_CLOSED_PREVQ1', 'TL_Closed_PrevQ1', 'TWL_Closed_PrevQ1',\n",
    "                    'DEMAT_CLOSED_PREV1YR', 'SEC_ACC_CLOSED_PREV1YR']\n",
    "combin['any_closed'] = combin[loan_closed_cols].max(axis = 1)\n",
    "\n",
    "live_loan_cols = [col for col in combin.columns if 'LIVE' in col]\n",
    "combin['any_live_loans'] = combin[live_loan_cols].max(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace all remaining nans with a large negative value\n",
    "combin.fillna(-9999,inplace = True)\n",
    "combin.replace('>', -9999, inplace = True)\n",
    "\n",
    "dt_cols = ['Req_Resolved_PrevQ1', 'Query_Resolved_PrevQ1', 'Complaint_Resolved_PrevQ1']\n",
    "for i in dt_cols:\n",
    "    combin[i] = pd.to_numeric(combin[i], errors='coerce')\n",
    "combin.drop(['Responders','UCIC_ID','zip','city','OCCUP_ALL_NEW'],axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_new = combin.iloc[300000:,:]\n",
    "train_new = combin.iloc[0:300000,:]\n",
    "y_all = train.Responders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove 0 variance features\n",
    "threshold = 0\n",
    "train_new = train_new.drop(train_new.std()[train_new.std() == threshold].index.values, axis=1)\n",
    "test_new = test_new[train_new.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model for choosing high performing features\n",
    "bst_lgb_2 = lgb.LGBMClassifier(learning_rate=0.1, colsample_bytree=0.8, max_depth=9, boosting_type='gbdt', objective='binary',\n",
    "                               num_leaves=255,\n",
    "                               n_estimators=300,\n",
    "                               n_jobs=8, seed = 99)\n",
    "bst_lgb_2.fit(train_new,y_all)\n",
    "\n",
    "# Feature selection using the above model to build a decent performing model\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "sfm = SelectFromModel(bst_lgb_2, threshold='median')\n",
    "sfm.fit(train_new,y_all)\n",
    "z = sfm.get_support(indices=False)\n",
    "zz = pd.DataFrame({'Feature':train_new.columns.values, 'ret': z})\n",
    "cols = np.array(zz.loc[zz.ret == 1,'Feature'])\n",
    "train_new = pd.DataFrame(sfm.transform(train_new),columns=cols)\n",
    "test_new = pd.DataFrame(sfm.transform(test_new),columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold = 10\n",
    "nrounds = 5000\n",
    "X = train_new.values\n",
    "y = y_all.values\n",
    "features = train_new.columns\n",
    "probs = 0\n",
    "y_test_pred_xgb = 0\n",
    "y_valid_pred_xgb = train['UCIC_ID'].to_frame()\n",
    "y_valid_pred_xgb['xgb'] = 0\n",
    "y_test_pred_lgb = 0\n",
    "y_valid_pred_lgb = train['UCIC_ID'].to_frame()\n",
    "y_valid_pred_lgb['lgb'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_xgb=test['UCIC_ID'].to_frame()\n",
    "sub_xgb['Responders']=0\n",
    "\n",
    "\n",
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eta'] = 0.01\n",
    "params['booster'] = 'gbtree'\n",
    "params['silent'] = True\n",
    "params['max_depth'] = 6\n",
    "params['subsample'] = 0.8\n",
    "params['colsample_bytree'] = 0.8\n",
    "params['tree_method'] = 'gpu_hist'\n",
    "params['eval_metric'] = 'auc'\n",
    "params['gamma'] = 0.05\n",
    "params['min_child_weight'] = 7\n",
    "\n",
    "# Take average of different xgboost models for better generalization\n",
    "\n",
    "skf = StratifiedKFold(n_splits=kfold, random_state=0, shuffle=True)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Using varied models for better generalization\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    if i <= 3:\n",
    "        params['max_depth'] = 6\n",
    "    elif i > 3 and i <= 6:\n",
    "        params['max_depth'] = 7\n",
    "    else:\n",
    "        params['max_depth'] = 8\n",
    "    print(' xgb kfold: {}  of  {} : '.format(i+1, kfold))\n",
    "    X_train, X_valid = X[train_index], X[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    d_train = xgb.DMatrix(X_train, y_train)\n",
    "    d_valid = xgb.DMatrix(X_valid, y_valid)\n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "    xgb_model = xgb.train(params, d_train, nrounds, watchlist, early_stopping_rounds=100,\n",
    "                          maximize=True, verbose_eval=100)\n",
    "    \n",
    "    # Generate validation predictions for this fold\n",
    "    pred = xgb_model.predict(xgb.DMatrix(X_valid))\n",
    "    y_valid_pred_xgb.iloc[test_index,1] = pred\n",
    "    \n",
    "    probs = xgb_model.predict(xgb.DMatrix(test_new[features].values), \n",
    "                        ntree_limit=xgb_model.best_ntree_limit+50)\n",
    "    y_test_pred_xgb += np.log(probs/(1-probs))\n",
    "    y_test_pred_xgb /= kfold  # Average test set predictions\n",
    "    y_test_pred_xgb =  1  /  ( 1 + np.exp(-y_test_pred_xgb) )\n",
    "    \n",
    "sub_xgb['Responders'] = y_test_pred_xgb\n",
    "sub_xgb.to_csv('xgb_tuned_averaged.csv', index=False, float_format='%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lgb Light gbm model \n",
    "kfold = 10\n",
    "sub_lgb=test['UCIC_ID'].to_frame()\n",
    "sub_lgb['Responders']=0\n",
    "\n",
    "params = {'metric': 'auc', 'learning_rate' : 0.01, 'max_depth':9, 'max_bin':20,  'objective': 'binary', \n",
    "          'feature_fraction': 0.8,'bagging_fraction':0.9,'bagging_freq':10,  'min_data': 500, 'num_leaves': 255}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=kfold, random_state=5, shuffle = True)\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "\n",
    "# Using varied models for better generalization\n",
    "    if i <= 3:\n",
    "        params['num_leaves'] = 127\n",
    "        params['max_depth'] = 0\n",
    "    elif i > 3 and i <= 6:\n",
    "        params['num_leaves'] = 90\n",
    "        params['max_depth'] = 0\n",
    "    else:\n",
    "        params['max_depth'] = 9\n",
    "        params['num_leaves'] = 255\n",
    "    print(' lgb kfold: {}  of  {} : '.format(i+1, kfold))\n",
    "    X_train, X_eval = X[train_index], X[test_index]\n",
    "    y_train, y_eval = y[train_index], y[test_index]\n",
    "    lgb_model = lgb.train(params, lgb.Dataset(X_train, label=y_train), nrounds, \n",
    "                  lgb.Dataset(X_eval, label=y_eval), verbose_eval=100, \n",
    "                  early_stopping_rounds=100)\n",
    "    sub_lgb['Responders'] += lgb_model.predict(test_new[features].values, \n",
    "                        num_iteration=lgb_model.best_iteration) / (kfold)\n",
    "sub_lgb.to_csv('lgb_tuned_averaged.csv', index=False, float_format='%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculating Normalized rank and making ensemble\n",
    "xgb_pred = pd.read_csv('xgb_tuned_averaged.csv')\n",
    "lgb_pred = pd.read_csv('lgb_tuned_averaged.csv')\n",
    "xgb_pred['rank/length'] = xgb_pred['Responders'].rank(ascending = 1)/xgb_pred.shape[0]\n",
    "lgb_pred['rank/length'] = lgb_pred['Responders'].rank(ascending = 1)/lgb_pred.shape[0]\n",
    "sub = pd.DataFrame({'UCIC_ID': test.UCIC_ID, 'Responders':0.45 * xgb_pred['rank/length'] + 0.55 * lgb_pred['rank/length']})\n",
    "sub.to_csv('sub_ens_rank_norm_xgb_lgb.csv',index=False,float_format='%.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
